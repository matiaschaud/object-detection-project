# PIPELINE DEFINITION
# Name: data-preparation-pipeline
# Description: Pipeline for preparing and splitting dataset
# Inputs:
#    random_state: int [Default: 42.0]
components:
  comp-download-dataset:
    executorLabel: exec-download-dataset
    inputDefinitions:
      parameters:
        output_dir:
          defaultValue: DATASET
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-output-file-contents:
    executorLabel: exec-output-file-contents
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-output-file-contents-2:
    executorLabel: exec-output-file-contents-2
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-split-dataset:
    executorLabel: exec-split-dataset
    inputDefinitions:
      artifacts:
        input_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        random_state:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        x_val_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_val_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-download-dataset:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - download_dataset
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'requests' 'boto3'\
          \ 'tqdm' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef download_dataset(output_dataset: Output[Dataset], output_dir:\
          \ str = \"DATASET\"):\n    import os\n    import requests\n    import tarfile\n\
          \    from tqdm import tqdm\n\n    # FULL Dataset\n    url = \"https://manning.box.com/shared/static/34dbdkmhahuafcxh0yhiqaf05rqnzjq9.gz\"\
          \n    downloaded_file = \"DATASET.gz\"\n\n    response = requests.get(url,\
          \ stream=True)\n    file_size = int(response.headers.get(\"Content-Length\"\
          , 0))\n    progress_bar = tqdm(total=file_size, unit=\"B\", unit_scale=True)\n\
          \n    with open(downloaded_file, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=1024):\n\
          \            progress_bar.update(len(chunk))\n            file.write(chunk)\n\
          \n    # Extract to the output directory\n    extraction_path = os.path.join(output_dataset.path,\
          \ output_dir)\n    os.makedirs(extraction_path, exist_ok=True)\n\n    with\
          \ tarfile.open(downloaded_file, 'r:gz') as tar:\n        tar.extractall(extraction_path)\n\
          \n"
        image: python:3.11
    exec-output-file-contents:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - output_file_contents
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef output_file_contents(dataset: Input[Dataset]):\n    import os\n\
          \n    def list_files(startpath):\n        for root, dirs, files in os.walk(startpath):\n\
          \            level = root.replace(startpath, '').count(os.sep)\n       \
          \     indent = ' ' * 4 * (level)\n            print(f'{indent}{os.path.basename(root)}/')\n\
          \            subindent = ' ' * 4 * (level + 1)\n            for f in files:\n\
          \                print(f'{subindent}{f}')\n\n    print(f\"Contents of {dataset.path}:\"\
          )\n    list_files(dataset.path)\n\n"
        image: python:3.10
    exec-output-file-contents-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - output_file_contents
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef output_file_contents(dataset: Input[Dataset]):\n    import os\n\
          \n    def list_files(startpath):\n        for root, dirs, files in os.walk(startpath):\n\
          \            level = root.replace(startpath, '').count(os.sep)\n       \
          \     indent = ' ' * 4 * (level)\n            print(f'{indent}{os.path.basename(root)}/')\n\
          \            subindent = ' ' * 4 * (level + 1)\n            for f in files:\n\
          \                print(f'{subindent}{f}')\n\n    print(f\"Contents of {dataset.path}:\"\
          )\n    list_files(dataset.path)\n\n"
        image: python:3.10
    exec-split-dataset:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - split_dataset
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef split_dataset(\n        random_state: int,\n        input_dataset:\
          \ Input[Dataset],\n        x_val_output: Output[Dataset],\n        y_val_output:\
          \ Output[Dataset]\n):\n    import os\n    import glob\n    import shutil\n\
          \    from sklearn.model_selection import train_test_split\n\n    # Adjust\
          \ paths to use input_dataset.path\n    images = list(glob.glob(os.path.join(input_dataset.path,\
          \ \"DATASET\", \"DATA\", \"images\", \"**\")))\n    labels = list(glob.glob(os.path.join(input_dataset.path,\
          \ \"DATASET\", \"DATA\", \"labels\", \"**\")))\n\n    train_ratio = 0.75\n\
          \    validation_ratio = 0.15\n    test_ratio = 0.10\n\n    # train is now\
          \ 75% of the entire data set\n    x_train, x_test, y_train, y_test = train_test_split(\n\
          \        images,\n        labels,\n        test_size=1 - train_ratio,\n\
          \        random_state=random_state\n    )\n\n    # test is now 10% of the\
          \ initial data set\n    # validation is now 15% of the initial data set\n\
          \    x_val, x_test, y_val, y_test = train_test_split(\n        x_test,\n\
          \        y_test,\n        test_size=test_ratio / (test_ratio + validation_ratio),\n\
          \        random_state=random_state\n    )\n\n    # Create output directories\n\
          \    os.makedirs(os.path.join(x_val_output.path, \"images\"), exist_ok=True)\n\
          \    os.makedirs(os.path.join(y_val_output.path, \"labels\"), exist_ok=True)\n\
          \n    def move_files(files, output_path, category):\n        for source_file\
          \ in files:\n            src = source_file.strip()\n            dest = os.path.join(output_path,\
          \ category, os.path.basename(source_file))\n            shutil.copy2(src,\
          \ dest)  # Using copy2 instead of move to preserve original files\n\n  \
          \  # Move validation files to output locations\n    move_files(x_val, x_val_output.path,\
          \ \"images\")\n    move_files(y_val, y_val_output.path, \"labels\")\n\n"
        image: python:3.11
pipelineInfo:
  description: Pipeline for preparing and splitting dataset
  name: data-preparation-pipeline
root:
  dag:
    tasks:
      download-dataset:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-download-dataset
        taskInfo:
          name: download-dataset
      output-file-contents:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-output-file-contents
        dependentTasks:
        - split-dataset
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: x_val_output
                producerTask: split-dataset
        taskInfo:
          name: output-file-contents
      output-file-contents-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-output-file-contents-2
        dependentTasks:
        - split-dataset
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: y_val_output
                producerTask: split-dataset
        taskInfo:
          name: output-file-contents-2
      split-dataset:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-split-dataset
        dependentTasks:
        - download-dataset
        inputs:
          artifacts:
            input_dataset:
              taskOutputArtifact:
                outputArtifactKey: output_dataset
                producerTask: download-dataset
          parameters:
            random_state:
              componentInputParameter: random_state
        taskInfo:
          name: split-dataset
  inputDefinitions:
    parameters:
      random_state:
        defaultValue: 42.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
